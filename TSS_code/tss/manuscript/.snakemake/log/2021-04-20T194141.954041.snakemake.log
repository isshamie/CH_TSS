Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	2	get_introns
	3

[Tue Apr 20 19:41:42 2021]
rule get_introns:
    input: /data/isshamie/genome/hamster/ncbi_anno_103/GCF_003668045.1_CriGri-PICR/GCF_003668045.1_CriGri-PICR_genomic.gff
    output: data/GCF/introns.bed
    jobid: 2
    wildcards: genome=GCF

[Tue Apr 20 19:43:21 2021]
Finished job 2.
1 of 3 steps (33%) done

[Tue Apr 20 19:43:21 2021]
rule get_introns:
    input: /data/isshamie/genome/hamster/syn20999279_picr.gff
    output: data/synapse/introns.bed
    jobid: 1
    wildcards: genome=synapse

[Tue Apr 20 19:44:58 2021]
Finished job 1.
2 of 3 steps (67%) done

[Tue Apr 20 19:44:58 2021]
localrule all:
    input: data/synapse/introns.bed, data/GCF/introns.bed
    jobid: 0

[Tue Apr 20 19:44:58 2021]
Finished job 0.
3 of 3 steps (100%) done
Complete log: /data/isshamie/TSS/Analysis/TSS_code/tss/manuscript/.snakemake/log/2021-04-20T194141.954041.snakemake.log
